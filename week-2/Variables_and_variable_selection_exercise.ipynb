{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee-v8I_P8rfp"
   },
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Exercise.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>\n",
    "\n",
    "# Exercise: Variables and variable selection\n",
    "Â© ExploreAI Academy\n",
    "\n",
    "In this exercise, we apply variance thresholding to select features from a dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITqrvAqq8xSC"
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this train, you should be able to:\n",
    "* Perform dummy variable encoding.\n",
    "* Implement variance thresholding in Python.\n",
    "* Use a variance threshold to filter out some features in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "We are provided with the `Crop_yield` dataset that contains various factors that could influence the yield of a particular crop across different regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df= pd.read_csv(\"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/Python/Crop_yield.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Our dataset contains several categorical features: `Region`, `Soil_Type`, and `Crop_Variety`. \n",
    "\n",
    "Use dummy variable encoding to convert these features into a numerical format suitable for model training. Verify the transformation by displaying the first five rows of the modified dataset.\n",
    "\n",
    "> How has the number of variables in our dataset changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "We want to determine which variables from the new dataset we will use for model training.\n",
    "\n",
    "Write a function `variance_thresholding` that will use variance thresholding to filter out features based on a variance threshold. The function should accept two parameters, which are the  DataFrame and the threshold value. It should return two DataFrames, one containing only the features that meet the variance threshold criterion, and one containing the scaled DataFrame.\n",
    "\n",
    "**Hint:** Scaling is crucial as it allows the variance thresholding to be applied uniformly across features. Read up on using the `MinMaxScaler()` function from the `sklearn.preprocessing` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Using the function we created in **Exercise 2**, apply variance threshold filtering to our encoded dataset, with a threshold of `0.03`. Compare the number of features before and after applying the variance threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Train two linear regression models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Using all the available features in our dummy encoded dataset from **Exercise 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Using only the features selected through the variance thresholding process in **Exercise 3**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Use the comments provided to better understand the various parts of the code solutions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply dummy variable encoding to the categorical variables\n",
    "df_encoded = pd.get_dummies(df, columns=[\"Region\", \"Soil_Type\", \"Crop_Variety\"], dtype=int)\n",
    "\n",
    "# Display the first few rows of the modified dataset to confirm the transformation\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the new number of columns\n",
    "df_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features have been successfully transformed into numerical format. Each unique value in these columns has been transformed into a separate column with a binary indicator, representing the presence `1` or absence `0` of that category in each row. Note: there has been an update on the `get_dummies` function, and the default output is now True/False.\n",
    "\n",
    "We examine the new number of columns using the `.shape` attribute. We can see that the columns have increased from `9` to `16`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_thresholding(df_encoded, threshold_value):\n",
    "    \n",
    "   # Splitting the dataset into features and target variable for scaling and training\n",
    "    X = df_encoded.drop(columns=['Yield']) \n",
    "    y = df_encoded['Yield']\n",
    "    \n",
    "    # Initialise and fit the scaler to the features only\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_features = scaler.fit_transform(X)\n",
    "    \n",
    "    # Convert the scaled features back to a DataFrame\n",
    "    df_scaled = pd.DataFrame(scaled_features, columns=X.columns)\n",
    "    \n",
    "    # Initialise the VarianceThreshold object with the specified threshold value\n",
    "    selector = VarianceThreshold(threshold=threshold_value)\n",
    "    \n",
    "    # Apply the selector to the scaled feature DataFrame\n",
    "    df_filtered_values = selector.fit_transform(df_scaled)\n",
    "    \n",
    "    # Convert the array result into a DataFrame with only the selected features\n",
    "    df_filtered = pd.DataFrame(df_filtered_values, columns=df_scaled.columns[selector.get_support(indices=True)])\n",
    "    \n",
    "    # Return the filtered DataFrame\n",
    "    return df_filtered, df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by scaling our features using the `MinMaxScaler()`.\n",
    "\n",
    "We then use the `threshold_value` passed as a parameter to filter out features whose variances fall below this value.\n",
    "\n",
    "The function eventually returns `df_filtered`, the DataFrame with features whose variances are above the given threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the variance_thresholding() function and pass the given threshold\n",
    "df_filtered, df_scaled = variance_thresholding(df_encoded, 0.03)\n",
    "\n",
    "# Compare the number of features before and after variance thresholding\n",
    "print(\"Number of features before variance thresholding:\", df_scaled.shape[1])\n",
    "print(\"Number of features after variance thresholding:\", df_filtered.shape[1])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a `0.03` threshold, the number of features has reduced from `15` to `13`, indicating that two of the features have been excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = df_encoded.drop(columns=['Yield'])\n", 
    "y = df_encoded['Yield']\n",
    "# Splitting both datasets into training and testing sets\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_all, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the model using all available features\n",
    "model_all = LinearRegression()\n",
    "model_all.fit(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(df_filtered, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the model using selected features\n",
    "model_filtered = LinearRegression()\n",
    "model_filtered.fit(X_train_filtered, y_train_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPZFCZhaikX+N2/Bg7W6SY+",
   "collapsed_sections": [],
   "name": "Search_algorithms.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "6b5ebbc2c6bde2831bc6c0426f75aca8137ccfc69d329557556ed73faee126ae"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
