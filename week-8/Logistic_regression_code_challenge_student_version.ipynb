{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "250ac15e",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Code_challenge.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662d169",
   "metadata": {},
   "source": [
    "# Graded code challenge: Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af890c",
   "metadata": {},
   "source": [
    "⚠️ **Note that this code challenge is graded and will contribute to your overall marks for this module.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d230d14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this coding challenge, you should be able to:\n",
    "- Implement a logistic regression model from scratch to solve a classification problem.\n",
    "- Apply learned concepts to preprocess data, fit the model, and evaluate its performance.\n",
    "- Enhance problem-solving skills by addressing a real-world classification challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68e80a4",
   "metadata": {},
   "source": [
    "## Honour code\n",
    "\n",
    "I **YOUR NAME**, **YOUR SURNAME**, confirm - by submitting this document - that the solutions in this notebook are a result of my own work.\n",
    "The use of StackOverflow, Google, and other online tools is permitted. However, copying a fellow student's code is not permissible and is considered a breach of the Honour code. Doing this will result in a mark of 0%.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Within this coding challenge, we begin our practical experience of building models for classification problems. We do so with a basic logistic regression model.   \n",
    "\n",
    "<br></br>\n",
    "\n",
    "<div align=\"center\" style=\"width: 600px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/credit_card.jpg\"\n",
    "     alt=\"Learn good habits to avoid modelling debt\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=600px/>\n",
    "Learn good habits to avoid modelling debt... Photo by <a href=\"https://unsplash.com/@rupixen?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\"> Rupixen.com </a> on Unsplash.\n",
    "</div>\n",
    "\n",
    "The structure of this notebook is as follows:\n",
    "\n",
    " - First, we will start off by loading and viewing the dataset.\n",
    " - We will see that the dataset has a mixture of both numerical and non-numerical features, that it contains values from different ranges, and that it contains a number of missing entries.\n",
    " - Based upon the observations above, we will preprocess the dataset to ensure the machine learning model we choose can make good predictions.\n",
    " - Once our data are in good shape, we will do some exploratory data analysis to build our intuitions.\n",
    " - Finally, we will build a machine learning model that can predict if an individual's application for a credit card will be accepted.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63dda70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0480d7ef",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "We'll use the [Credit Card Approval dataset](http://archive.ics.uci.edu/ml/datasets/credit+approval) from the UCI Machine Learning Repository.\n",
    "    \n",
    "We explore the variables within this dataset in the sections below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b80c841",
   "metadata": {},
   "source": [
    "### Reading in the data\n",
    "\n",
    "First, loading and viewing the dataset. We find that since this data are confidential, the contributor of the dataset has anonymised the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977b6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/89fee4463f428f55d31a254924e18501a3c468c3/Data/classification_sprint/cc_approvals.data',header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c798da3",
   "metadata": {},
   "source": [
    "The output may appear a bit confusing at first glance, but let's try to figure out the most important features of a credit card application. The features of this dataset have been anonymised to protect privacy, but [this blog](http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html) gives us a pretty good overview of the probable features. The probable features in a typical credit card application are <code>Gender</code>, <code>Age</code>, <code>Debt</code>, <code>Married</code>, <code>BankCustomer</code>, <code>EducationLevel</code>, <code>Ethnicity</code>, <code>YearsEmployed</code>, <code>PriorDefault</code>, <code>Employed</code>, <code>CreditScore</code>, <code>DriversLicense</code>, <code>Citizen</code>, <code>ZipCode</code>, <code>Income</code>, and finally, <code>ApprovalStatus</code>. \n",
    "\n",
    "This gives us a pretty good starting point, and we can map these features with respect to the columns in the output.   \n",
    "\n",
    "As we can see from our first glance at the data, the dataset has a mixture of numerical and non-numerical features. This can be fixed with some preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e75c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f594337",
   "metadata": {},
   "source": [
    "\n",
    "<li>Our dataset contains both numeric and non-numeric data (specifically data that are of <code>float64</code>, <code>int64</code>, and <code>object</code> types). Specifically, features 2, 7, 10, and 14 contain numeric values (of types float64, float64, int64, and int64, respectively) and all the other features contain non-numeric values.</li>\n",
    "<li>The dataset also contains values from several ranges. Some features have a value range of 0 to 28, some have a range of 2 to 67, and some have a range of 1017 to 100000.\n",
    "<li>Finally, the dataset has missing values, which we'll take care of in this task. The missing values in the dataset are labelled with '?', which can be seen in the last cell's output.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f12d37",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9defc19",
   "metadata": {},
   "source": [
    "## Question 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee85e1c6",
   "metadata": {},
   "source": [
    "Write a function to clean the given data. The function should:\n",
    "* Replace the '?'s with NaN.\n",
    "* Impute the missing values with mean imputation.\n",
    "* Impute the missing values of non-numeric columns with the most frequent values as present in the respective columns.\n",
    "\n",
    "_**Function specifications:**_\n",
    "* Should take a Pandas DataFrame and column name as input and return a list as an output.\n",
    "* The list should be a count of unique values in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d3e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def data_cleaning(data, column_name):\n",
    "    # your code here\n",
    "    return\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efe4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaning(df, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d20508",
   "metadata": {},
   "source": [
    "_**Expected outputs:**_\n",
    "    \n",
    "\n",
    ">```\n",
    "data_cleaning(df, 0) == [480, 210]\n",
    "data_cleaning(df, 9) == [395, 295]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8294d3aa",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc5177",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1721f24e",
   "metadata": {},
   "source": [
    "Write a function to preprocess the data so that we can run it through the classifier. The function should:\n",
    "* Convert the non-numeric data into numeric using sklearn's ```labelEncoder```. \n",
    "* Drop the features 11 and 13 and convert the DataFrame to a NumPy array.\n",
    "* Split the data into features and labels.\n",
    "* Standardise the features using sklearn's ```MinMaxScaler```.\n",
    "* Split the data into 80% training and 20% testing data.\n",
    "* Use the `train_test_split` method from `sklearn` to do this.\n",
    "* Set random_state to equal 42 for this internal method. \n",
    "\n",
    "_**Function specifications:**_\n",
    "* Should take a DataFrame as input.\n",
    "* The input should be the raw unprocessed DataFrame df.\n",
    "* Should return two `tuples` of the form `(X_train, y_train), (X_test, y_test)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb67622",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def data_preprocess(df):  \n",
    "    # your code here\n",
    "    return (0, 0), (0, 0)\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80386b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = data_preprocess(df)\n",
    "print(X_train[:1])\n",
    "print(y_train[:1])\n",
    "print(X_test[:1])\n",
    "print(y_test[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13516e81",
   "metadata": {},
   "source": [
    "_**Expected outputs:**_\n",
    "\n",
    "```python\n",
    "(X_train, y_train), (X_test, y_test) = data_preprocess(df)\n",
    "print(X_train[:2])\n",
    "print(y_train[:2])\n",
    "print(X_test[:2])\n",
    "print(y_test[:2])\n",
    "```\n",
    "\n",
    "> ```\n",
    "[[1.         0.25787966 0.48214286 1.         1.         0.42857143\n",
    "  0.33333333 0.         0.         0.         0.         0.\n",
    "  0.        ]]\n",
    "[1.]\n",
    "[[0.5        1.         0.05357143 0.66666667 0.33333333 0.42857143\n",
    "  0.33333333 0.         0.         1.         0.02985075 0.\n",
    "  0.00105   ]]\n",
    "[1.]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd1d11",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba988d",
   "metadata": {},
   "source": [
    "## Question 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603febfb",
   "metadata": {},
   "source": [
    "Now that we have formatted our data, we can fit a model using sklearn's `LogisticRegression` class with solver 'lbfgs'. Write a function that will take as input `(X_train, y_train)` that we created previously and return a trained model.\n",
    "\n",
    "_**Function specifications:**_\n",
    "* Should take two NumPy `arrays` as input in the form `(X_train, y_train)`.\n",
    "* The returned model should be fitted to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def train_model(X_train, y_train):\n",
    "    # your code here\n",
    "    return \n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f66e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = train_model(X_train, y_train)\n",
    "print(lm.intercept_[0])\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bd3417",
   "metadata": {},
   "source": [
    "_**Expected outputs:**_\n",
    "\n",
    "```python\n",
    "lm = train_model(X_train, y_train)\n",
    "print(lm.intercept_[0])\n",
    "print(lm.coef_)\n",
    "```\n",
    "```\n",
    "1.5068926456005878\n",
    "[[ 0.25237869 -0.22847881 -0.01779302  2.00977742  0.23903441 -0.29504922\n",
    "  -0.08952344 -0.83468871 -3.48756932 -1.07648711 -0.83688921  0.07860585\n",
    "  -1.3077735 ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da86dc23",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab990a",
   "metadata": {},
   "source": [
    "### Question 3.2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5401ffb6",
   "metadata": {},
   "source": [
    "AUC – ROC curve is a performance measurement for classification problems at various threshold settings. ROC is a probability curve and AUC represents the degree or measure of separability. It tells how much the model is capable of distinguishing between classes. Write a function which returns the AUC – ROC score of your trained model when tested with the test set.\n",
    "\n",
    "_**Function specifications:**_\n",
    "* Should take the fitted model and two NumPy `arrays` `X_test, y_test` as input.\n",
    "* Should return a `float` of the AUC – ROC score of the model. This number should be between zero and one.\n",
    "\n",
    "_**Hint:**_  Use the positive class's probability as the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d5f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def roc_score(lm, X_test, y_test):\n",
    "    # your code here\n",
    "    return \n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6acddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_score(lm,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1225354",
   "metadata": {},
   "source": [
    "_**Expected outputs:**_\n",
    "    \n",
    "```python\n",
    "print(roc_score(lm,X_test,y_test))\n",
    "```\n",
    ">```\n",
    "0.8865546218487395\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a7ff9b",
   "metadata": {},
   "source": [
    "### Question 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8492d4",
   "metadata": {},
   "source": [
    "Write a function which calculates the accuracy, precision, recall, and F1 scores.\n",
    "\n",
    "_**Function specifications:**_\n",
    "* Should take the fitted model and two NumPy `arrays` `X_test, y_test` as input.\n",
    "* Should return a tuple in the form (`Accuracy`, `Precision`, `Recall`, `F1-Score`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bcaedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def scores(lm, X_test, y_test):\n",
    "    # your code here\n",
    "    return (0, 0, 0, 0)\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31225569",
   "metadata": {},
   "outputs": [],
   "source": [
    "(accuracy, precision, recall, f1) = scores(lm, X_test, y_test)    \n",
    "\n",
    "print('Accuracy: %f' % accuracy)\n",
    "print('Precision: %f' % precision)\n",
    "print('Recall: %f' % recall)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0b488",
   "metadata": {},
   "source": [
    "_**Expected outputs:**_\n",
    "```python\n",
    "(accuracy, precision, recall, f1) = scores(lm,X_test,y_test)\n",
    "    \n",
    "print('Accuracy: %f' % accuracy)\n",
    "print('Precision: %f' % precision)\n",
    "print('Recall: %f' % recall)\n",
    "print('F1 score: %f' % f1)\n",
    "```\n",
    "> ```\n",
    "Accuracy: 0.833333\n",
    "Precision: 0.846154\n",
    "Recall: 0.808824\n",
    "F1 score: 0.827068\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
